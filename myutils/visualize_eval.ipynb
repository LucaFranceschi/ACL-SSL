{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8daaf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "import os, re, shutil\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce29c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thr(ss: str):\n",
    "    match = re.search(r'\\(([\\d\\.]+)\\)', ss)\n",
    "    if match != None:\n",
    "        return float(match.group(1))\n",
    "\n",
    "def get_metric(ss: str):\n",
    "    match = re.search(r'\\([\\d\\.]+\\)_(.*)$', ss)\n",
    "    if match != None:\n",
    "        return match.group(1)\n",
    "\n",
    "def get_audio_type(ss: str):\n",
    "    match = re.search(r'(std|silence|noise)', ss)\n",
    "    if match != None:\n",
    "        return match.group(1)\n",
    "\n",
    "def get_dataset(ss: str):\n",
    "    match = re.search(r'(avs_ms3|avs_s4|vggss|exvggss|vggsound|flickr|exflickr|avatar_one_bb|avatar_one_seg)', ss)\n",
    "    if match != None:\n",
    "        return match.group(1)\n",
    "\n",
    "def get_epoch(ss: str):\n",
    "    match = re.search(r'epoch(\\d+|best)', ss)\n",
    "    if match != None:\n",
    "        epoch = match.group(1)\n",
    "        if epoch == 'best':\n",
    "            epoch = 20\n",
    "        return int(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b0530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nested_tb_logs(root_dir):\n",
    "    all_data = []\n",
    "\n",
    "    # Walk through the directory tree\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        # Check if there are any tfevents files in this specific folder\n",
    "        if any(f.startswith(\"events.out.tfevents\") for f in files):\n",
    "            # Extract the folder name to use as a category/run label\n",
    "\n",
    "            # Initialize accumulator for this specific subdirectory\n",
    "            acc = event_accumulator.EventAccumulator(root)\n",
    "            acc.Reload()\n",
    "\n",
    "            for tag in acc.Tags()['scalars']:\n",
    "                events = acc.Scalars(tag)\n",
    "                df_temp = pd.DataFrame(events)\n",
    "\n",
    "                # We add 'metric' (e.g., value) and 'sub_dir' (e.g., test_noise_avs...)\n",
    "                df_temp['metric_tag'] = tag\n",
    "                df_temp['run_group'] = root\n",
    "\n",
    "                all_data.append(df_temp)\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"No event files found in the specified path.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Combine all found data\n",
    "    master_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    # Cleanup: Convert time and reorder columns\n",
    "    master_df['wall_time'] = pd.to_datetime(master_df['wall_time'], unit='s')\n",
    "\n",
    "    return master_df\n",
    "\n",
    "def load_eval(path, run_name):\n",
    "    df = load_nested_tb_logs(path)\n",
    "    print(f\"Loaded {len(df)} data points.\")\n",
    "\n",
    "    df['threshold'] = df['run_group'].apply(lambda x: get_thr(str(x)))\n",
    "    df['metric'] = df['run_group'].apply(lambda x: get_metric(str(x)))\n",
    "    df['audio_type'] = df['metric_tag'].apply(lambda x: get_audio_type(str(x)))\n",
    "    df['dataset'] = df['run_group'].apply(lambda x: get_dataset(str(x)))\n",
    "    df['epoch'] = df['run_group'].apply(lambda x: get_epoch(str(x)))\n",
    "    df.drop(['wall_time', 'metric_tag', 'run_group'],axis=1, inplace=True)\n",
    "    df = df.assign(run=run_name)\n",
    "\n",
    "    return df\n",
    "\n",
    "def print_metrics(df):\n",
    "    filtered_df = df[\n",
    "        (df['threshold'] == 0.5) &\n",
    "        (df['metric'].isin(['cIoU_hat', 'AUC', 'pIA_hat', 'AUC_N', 'mIoU', 'Fmeasure']))\n",
    "    ]\n",
    "\n",
    "    # 2. Pivot the data\n",
    "    # index: what you want as rows\n",
    "    # columns: what you want as side-by-side columns\n",
    "    # values: the numbers to fill the table\n",
    "    pivot_df = filtered_df.pivot_table(\n",
    "        index=['dataset', 'epoch'],\n",
    "        columns=['audio_type', 'metric'],\n",
    "        values='value',\n",
    "    )\n",
    "\n",
    "    # Define the desired order for each audio_type\n",
    "    std_cols = [('std', m) for m in ['cIoU_hat', 'AUC', 'mIoU', 'Fmeasure']]\n",
    "    silence_cols = [('silence', m) for m in ['pIA_hat', 'AUC_N']]\n",
    "    noise_cols = [('noise', m) for m in ['pIA_hat', 'AUC_N']]\n",
    "\n",
    "    # Combine them into one ordered list\n",
    "    target_columns = std_cols + silence_cols + noise_cols\n",
    "\n",
    "    # Reindex the columns to the new order\n",
    "    # errors='ignore' ensures it doesn't crash if a specific metric is missing for one type\n",
    "    pivot_df = pivot_df.reindex(columns=target_columns)\n",
    "\n",
    "    pd.options.display.float_format = \"{:,.3f}\".format\n",
    "    pd.options.display.max_columns = None\n",
    "    pd.options.display.width = 1000 # Increased width to prevent wrapping\n",
    "\n",
    "    print(pivot_df)\n",
    "    return pivot_df\n",
    "\n",
    "def plot_all_metrics(df):\n",
    "    color_palette = {}\n",
    "    for dataset, color in zip(sorted(df['dataset'].unique()), sns.color_palette(n_colors=df['dataset'].nunique()).as_hex()):\n",
    "        color_palette[dataset] = color\n",
    "    # 1. Setup the style\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    # 2. Define strict mappings\n",
    "    # Mapping line styles to audio types\n",
    "    style_map = {\n",
    "        'std': (None, None),  # Solid\n",
    "        'noise': (5, 5),      # Dashed\n",
    "        'silence': (1, 2)     # Dotted\n",
    "    }\n",
    "\n",
    "    # 3. Get list of unique metrics\n",
    "    metrics = df['metric'].unique()\n",
    "\n",
    "    for m in metrics:\n",
    "        subset = df[df['metric'] == m].copy()\n",
    "        subset = subset.sort_values('threshold')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # 4. Create the lineplot with the fixed palette\n",
    "        ax = sns.lineplot(\n",
    "            data=subset,\n",
    "            x='threshold',\n",
    "            y='value',\n",
    "            hue='dataset',\n",
    "            palette=color_palette,  # Force consistent colors\n",
    "            style='audio_type',\n",
    "            dashes=style_map,\n",
    "            markers=True,\n",
    "            linewidth=2\n",
    "        )\n",
    "\n",
    "        # 5. Formatting\n",
    "        plt.title(f\"Metric: {m}\", fontsize=15, fontweight='bold')\n",
    "        plt.xlabel(\"Threshold\")\n",
    "        plt.ylabel(\"Value\")\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.xticks(np.arange(0, 1.1, 0.1))\n",
    "        plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "        plt.xlim(0, 1)\n",
    "        precision = 1\n",
    "        plt.ylim(np.true_divide(np.floor(subset['value'].min() * 10**precision), 10**precision),\n",
    "        np.true_divide(np.ceil(subset['value'].max() * 10**precision), 10**precision))\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "def plot_all_runs(merged_df):\n",
    "    merged_df = merged_df[\n",
    "        (merged_df['threshold'] == 0.5) &\n",
    "        (merged_df['dataset'] == 'avatar_one_seg')\n",
    "    ]\n",
    "\n",
    "    df = merged_df[merged_df['run'] != 'baseline']\n",
    "\n",
    "    color_palette = {}\n",
    "    for dataset, color in zip(sorted(df['run'].unique()), sns.color_palette(n_colors=df['run'].nunique()).as_hex()):\n",
    "        color_palette[dataset] = color\n",
    "\n",
    "    # 1. Setup the style\n",
    "    sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "    # 2. Define strict mappings\n",
    "    # Mapping line styles to audio types\n",
    "    style_map = {\n",
    "        'std': (None, None),  # Solid\n",
    "        'noise': (5, 5),      # Dashed\n",
    "        'silence': (1, 2)     # Dotted\n",
    "    }\n",
    "\n",
    "    df = df.sort_values('threshold')\n",
    "\n",
    "    # 3. Get list of unique metrics\n",
    "    metrics = df['metric'].unique()\n",
    "\n",
    "    for m in metrics:\n",
    "        subset = df[df['metric'] == m].copy()\n",
    "        subset = subset.sort_values('threshold')\n",
    "\n",
    "        baseline_value = merged_df[\n",
    "            (merged_df['run'] == 'baseline') &\n",
    "            (merged_df['metric'] == m)\n",
    "        ]['value'].to_list()[0]\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        plt.hlines(baseline_value, 0, 20, label='baseline', linestyles='dashed')\n",
    "\n",
    "        # 4. Create the lineplot with the fixed palette\n",
    "        ax = sns.lineplot(\n",
    "            data=subset,\n",
    "            x='epoch',\n",
    "            y='value',\n",
    "            hue='run',\n",
    "            palette=color_palette,  # Force consistent colors\n",
    "            style='audio_type',\n",
    "            dashes=style_map,\n",
    "            markers=True,\n",
    "            linewidth=2\n",
    "        )\n",
    "\n",
    "        # 5. Formatting\n",
    "        plt.title(f\"Evaluation @(threshold=0.5, avatar_seg, {m})\", fontsize=15, fontweight='bold')\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Value\")\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "        plt.xticks(range(0, 21, 2))\n",
    "        precision = 1\n",
    "        plt.ylim(\n",
    "            np.true_divide(np.floor(min(subset['value'].min(), baseline_value) * 10**precision), 10**precision),\n",
    "            np.true_divide(np.ceil(max(subset['value'].max(), baseline_value) * 10**precision), 10**precision)\n",
    "        )\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388288bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrong_list = list(filter(lambda x: re.search(r'\\(s4\\)', x), os.listdir(path)))\n",
    "# corrected_list = [x.replace('(s4)', '_s4') for x in wrong_list]\n",
    "\n",
    "# for wr, corr in zip(wrong_list, corrected_list):\n",
    "#     # print(os.path.join(path, wr), '-->', os.path.join(path, corr))\n",
    "#     shutil.move(os.path.join(path, wr), os.path.join(path, corr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64665447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"../train_outputs/2059323/Test_record/ACL_ViT16_aclifa_2gpu/tensorboard/epoch8\"\n",
    "# path = \"../train_outputs/2070501/Test_record/ACL_ViT16_Exp_ACL_v1/tensorboard/epochbest/\"\n",
    "# path = \"../train_outputs/merged_baseline_test/Test_record/Test_record/ACL_ViT16_Exp_ACL_v1/tensorboard/epochbest\"\n",
    "baseline_eval = load_eval(\"../train_outputs/merged_baseline_test/Test_record/ACL_ViT16_Exp_ACL_v1/tensorboard\", 'baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa731bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = print_metrics(baseline_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aabe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrained_baseline = load_eval(\"../train_outputs/2059438/Test_record/ACL_ViT16_aclifa_2gpu/tensorboard\", 'retrained_baseline_B8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8154a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = print_metrics(retrained_baseline[retrained_baseline['epoch'] == 14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a50ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval = pd.concat([baseline_eval, retrained_baseline])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4b7271",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6efd419",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_runs(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc3355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_metrics(baseline_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a92b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_metrics(retrained_baseline[retrained_baseline['epoch'] == 14])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
